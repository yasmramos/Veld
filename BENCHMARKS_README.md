# üöÄ Sistema de Benchmarks Automatizado - Veld DI Framework

Este sistema ejecuta autom√°ticamente todos los benchmarks del proyecto Veld DI Framework y genera reportes detallados tanto localmente como en CI/CD.

---

## üéØ Caracter√≠sticas del Sistema

### ‚úÖ **Automatizaci√≥n Completa**
- Ejecuci√≥n autom√°tica de todos los tipos de benchmarks
- Generaci√≥n de reportes en markdown
- An√°lisis de tendencias de performance
- Detecci√≥n autom√°tica de regressions
- Notificaciones en pull requests

### üìä **Tipos de Benchmarks**
1. **JMH Benchmarks**: Performance extrema con Java Microbenchmark Harness
2. **Simple Benchmarks**: Pruebas b√°sicas de funcionalidad
3. **Strategic Benchmarks**: An√°lisis de casos de uso espec√≠ficos
4. **JMH Standalone**: Benchmarks independientes
5. **Unit Tests**: Verificaci√≥n de funcionalidad

### ü§ñ **CI/CD Integration**
- GitHub Actions workflow completo
- Ejecuci√≥n en m√∫ltiples versiones de Java (11, 17)
- Artifacts guardados por 30 d√≠as
- Reportes consolidados autom√°ticos

---

## üöÄ Uso del Sistema

### **Ejecuci√≥n Local**

```bash
cd /workspace/Veld

# Ejecutar todos los benchmarks
./run_all_benchmarks.sh

# O ejecutar manualmente cada componente
./mvnw -pl veld-benchmark -am clean compile
java -cp veld-benchmark/target/classes:... com.veld.benchmark.SimpleBenchmark
```

### **CI/CD Autom√°tico**

El sistema se ejecuta autom√°ticamente en:

- **Push a main branch**
- **Pull Requests**
- **Ejecuci√≥n diaria** (02:00 UTC)

### **Configuraci√≥n Manual**

```bash
# Clonar y configurar
git clone https://github.com/yasmramos/Veld.git
cd Veld

# Instalar dependencias
./mvnw clean install

# Ejecutar benchmarks
./run_all_benchmarks.sh
```

---

## üìÅ Estructura de Archivos

```
Veld/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ benchmarks.yml              # Workflow de CI/CD
‚îú‚îÄ‚îÄ benchmark-reports/              # Reportes generados
‚îÇ   ‚îú‚îÄ‚îÄ benchmark-report.md         # Reporte principal
‚îÇ   ‚îú‚îÄ‚îÄ consolidated-report.md      # Reporte consolidado
‚îÇ   ‚îú‚îÄ‚îÄ performance-analysis.md     # An√°lisis de performance
‚îÇ   ‚îú‚îÄ‚îÄ execution-summary.md        # Resumen de ejecuci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ history/                    # Hist√≥rico de ejecuciones
‚îÇ   ‚îî‚îÄ‚îÄ analysis/                   # An√°lisis detallados
‚îú‚îÄ‚îÄ veld-benchmark/                 # M√≥dulo de benchmarks
‚îÇ   ‚îú‚îÄ‚îÄ src/main/java/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ com/veld/benchmark/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Phase1OptimizationBenchmark.java
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ SimpleBenchmark.java
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ StrategicBenchmark.java
‚îÇ   ‚îî‚îÄ‚îÄ run-strategic-benchmarks.sh # Script estrat√©gico
‚îú‚îÄ‚îÄ Scripts de Generaci√≥n/
‚îÇ   ‚îú‚îÄ‚îÄ generate_benchmark_report.py
‚îÇ   ‚îú‚îÄ‚îÄ consolidate_benchmark_reports.py
‚îÇ   ‚îî‚îÄ‚îÄ performance_analysis.py
‚îî‚îÄ‚îÄ run_all_benchmarks.sh           # Script principal local
```

---

## üìä Tipos de Reportes

### 1. **Reporte Principal** (`benchmark-report.md`)
- Resumen ejecutivo de benchmarks
- M√©tricas de rendimiento clave
- Comparaci√≥n con frameworks tradicionales
- An√°lisis t√©cnico de optimizaciones
- Recomendaciones de producci√≥n

### 2. **Reporte Consolidado** (`consolidated-report.md`)
- Comparaci√≥n entre Java 11 y Java 17
- Resultados de m√∫ltiples ejecuciones
- An√°lisis comparativo de versiones
- Artifacts y archivos generados

### 3. **An√°lisis de Performance** (`performance-analysis.md`)
- Tendencias de rendimiento
- Detecci√≥n de regressions
- Alertas autom√°ticas
- Recomendaciones de optimizaci√≥n

### 4. **Resumen de Ejecuci√≥n** (`execution-summary.md`)
- Estado de cada componente
- Archivos generados
- Pr√≥ximos pasos recomendados

---

## üîß Configuraci√≥n de CI/CD

### **GitHub Actions Workflow**

```yaml
name: Veld DI Framework - Benchmarks & Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Diario a las 02:00 UTC

jobs:
  benchmarks:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        java-version: [11, 17]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up JDK
      uses: actions/setup-java@v4
      with:
        java-version: ${{ matrix.java-version }}
    
    - name: Run all benchmarks
      run: ./run_all_benchmarks.sh
    
    - name: Upload results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark-reports/
```

### **Variables de Entorno**

```bash
# Configurar en GitHub Secrets
GITHUB_TOKEN=ghp_...
MAVEN_SETTINGS=...
```

---

## üìà M√©tricas Monitoreadas

### **Performance Core**
- **Throughput**: Operaciones por segundo
- **Latency**: Tiempo de respuesta
- **Memory Usage**: Uso de memoria heap
- **GC Pressure**: Presi√≥n del garbage collector

### **Framework-Specific**
- **Injection Speed**: Velocidad de inyecci√≥n de dependencias
- **Startup Time**: Tiempo de inicializaci√≥n
- **Reflection Elimination**: Porcentaje de reflection eliminado
- **Bytecode Generation**: Eficiencia de generaci√≥n

### **Comparative Metrics**
- **vs Spring DI**: Comparaci√≥n de velocidad
- **vs Guice**: Benchmarks relativos
- **vs Dagger**: Performance comparativa

---

## üö® Alertas y Notificaciones

### **Tipos de Alertas**
1. **Regressions**: Performance degrad√≥ > 10%
2. **Test Failures**: Tests fallaron > 5%
3. **Memory Leaks**: Aumento significativo de memoria
4. **Compilation Errors**: Errores de compilaci√≥n

### **Canales de Notificaci√≥n**
- **GitHub Comments**: En pull requests
- **GitHub Issues**: Para regressions cr√≠ticas
- **Email**: Para alertas de alta severidad
- **Slack/Teams**: Configuraci√≥n personalizada

---

## üîß Personalizaci√≥n

### **Configurar Benchmarks**

Editar `Phase1OptimizationBenchmark.java`:
```java
@BenchmarkMode(Mode.Throughput)
@OutputTimeUnit(TimeUnit.MICROSECONDS)
@Warmup(iterations = 3, time = 1, timeUnit = TimeUnit.SECONDS)
@Measurement(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)
@Fork(1)
public class Phase1OptimizationBenchmark {
    // Configurar benchmarks espec√≠ficos
}
```

### **Agregar Nuevos Benchmarks**

1. Crear clase en `veld-benchmark/src/main/java/`
2. Anotar con `@Benchmark`
3. Implementar m√©todo benchmark
4. Agregar al workflow de CI/CD

### **Personalizar Reportes**

Modificar scripts de generaci√≥n:
- `generate_benchmark_report.py`: Reporte principal
- `performance_analysis.py`: An√°lisis de tendencias
- `consolidate_benchmark_reports.py`: Consolidaci√≥n

---

## üìö Documentaci√≥n Adicional

### **Gu√≠as T√©cnicas**
- [Benchmark Development Guide](./docs/benchmark-development.md)
- [Performance Tuning Guide](./docs/performance-tuning.md)
- [CI/CD Configuration](./docs/cicd-configuration.md)

### **APIs y Referencias**
- [JMH Documentation](https://openjdk.java.net/projects/code-tools/jmh/)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Maven Documentation](https://maven.apache.org/)

---

## ü§ù Contribuci√≥n

### **Agregar Benchmarks**
1. Fork del repositorio
2. Crear branch para nueva feature
3. Implementar benchmark
4. Agregar tests correspondientes
5. Actualizar documentaci√≥n
6. Crear Pull Request

### **Reportar Issues**
- Performance regressions
- Benchmarks faltantes
- Errores en reportes
- Mejoras de CI/CD

---

## üìû Soporte

- **Issues**: [GitHub Issues](https://github.com/yasmramos/Veld/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yasmramos/Veld/discussions)
- **Email**: yasmramos@github.com

---

## üìÑ Licencia

Este sistema de benchmarks es parte del proyecto Veld DI Framework y est√° bajo la licencia Apache 2.0.

---

**√öltima actualizaci√≥n**: 2025-12-12 09:05:25  
**Versi√≥n**: 1.0.0  
**Autor**: MiniMax Agent