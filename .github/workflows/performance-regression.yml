name: Performance Regression Tests

on:
  push:
    branches: [ "main", "develop" ]
    paths:
      - '**.java'
      - 'pom.xml'
      - '.github/workflows/performance-regression.yml'
      - 'veld-benchmark/**'
  pull_request:
    branches: [ "main", "develop" ]
  workflow_dispatch:
    inputs:
      threshold_mode:
        description: 'Threshold strictness level'
        required: true
        default: 'normal'
        type: choice
        options:
          - strict
          - normal
          - lenient

jobs:
  performance-regression:
    runs-on: ubuntu-latest

    timeout-minutes: 30

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up JDK 17
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'
        cache: maven

    - name: Display environment
      run: |
        echo "=== Environment ==="
        echo "Java version:"
        java -version
        echo "Maven version:"
        mvn -version
        echo "Available memory:"
        free -h
        echo "CPU cores:"
        nproc

    # Build the framework first
    - name: Build Veld Framework
      run: |
        echo "=== Building Veld Framework ==="
        mvn clean install -DskipTests -Pbenchmark -Dmaven.javadoc.skip=true
      env:
        MAVEN_OPTS: "-Xmx2g -XX:+UseG1GC"
      timeout-minutes: 15

    # Build benchmark module
    - name: Build Benchmark Module
      run: |
        echo "=== Building Benchmark Module ==="
        cd veld-benchmark
        mvn clean package -DskipTests
      env:
        MAVEN_OPTS: "-Ddepgraph.skip=true"
      timeout-minutes: 10

    # Run quick benchmarks for regression testing
    - name: Run Quick Benchmarks
      run: |
        echo "=== Running Quick Benchmarks for Regression ==="
        cd veld-benchmark

        # Run key benchmarks for regression testing
        java -Xmx1g -jar target/veld-benchmark.jar \
          ".*Injection.*" \
          -f 1 -wi 1 -i 2 -bs 1 \
          -rf json \
          -rff target/regression-injection-results.json

        java -Xmx1g -jar target/veld-benchmark.jar \
          ".*Startup.*" \
          -f 1 -wi 1 -i 2 -bs 1 \
          -rf json \
          -rff target/regression-startup-results.json

        java -Xmx1g -jar target/veld-benchmark.jar \
          ".*Throughput.*" \
          -f 1 -wi 1 -i 2 -bs 1 \
          -rf json \
          -rff target/regression-throughput-results.json

        java -Xmx1g -jar target/veld-benchmark.jar \
          ".*Memory.*" \
          -f 1 -wi 1 -i 2 -bs 1 \
          -rf json \
          -rff target/regression-memory-results.json

        # Combine results
        echo '{"benchmarks": {' > target/benchmark-results.json
        tail -n +2 target/regression-injection-results.json | head -n -1 >> target/benchmark-results.json
        echo ',' >> target/benchmark-results.json
        tail -n +2 target/regression-startup-results.json | head -n -1 >> target/benchmark-results.json
        echo ',' >> target/benchmark-results.json
        tail -n +2 target/regression-throughput-results.json | head -n -1 >> target/benchmark-results.json
        echo ',' >> target/benchmark-results.json
        tail -n +2 target/regression-memory-results.json | head -n -1 >> target/benchmark-results.json
        echo '}}' >> target/benchmark-results.json

        echo "‚úÖ Quick benchmarks completed"
        ls -la target/regression-*.json
      timeout-minutes: 10

    # Run regression validation
    - name: Validate Performance Regression
      run: |
        echo "=== Validating Performance Regression ==="
        cd veld-benchmark

        # Compile and run regression test
        echo "Compiling regression test..."
        javac -cp target/veld-benchmark.jar:target/classes src/main/java/io/github/yasmramos/veld/benchmark/regression/PerformanceRegressionTest.java

        echo "Running regression test..."
        java -cp "target/veld-benchmark.jar:target/classes:src/main/java" \
          io.github.yasmramos.veld.benchmark.regression.PerformanceRegressionTest \
          --run-benchmarks

        echo "‚úÖ Regression validation completed"
      timeout-minutes: 5

    # Store results for comparison with future runs
    - name: Store Baseline Results
      run: |
        echo "=== Storing Baseline Results ==="
        cd veld-benchmark

        # Create baseline directory
        mkdir -p target/baseline/${{ github.sha }}

        # Copy current results as baseline for future comparisons
        cp target/regression-*.json target/baseline/${{ github.sha }}/ 2>/dev/null || true
        cp target/benchmark-results.json target/baseline/${{ github.sha }}/ 2>/dev/null || true

        # Update latest baseline symlink
        rm -f target/baseline/latest
        ln -sf ${{ github.sha }} target/baseline/latest

        echo "‚úÖ Baseline stored for commit ${{ github.sha }}"
        ls -la target/baseline/

    # Generate regression report
    - name: Generate Regression Report
      run: |
        echo "=== Generating Regression Report ==="
        cd veld-benchmark

        cat > REGRESSION_REPORT.md << 'EOF'
# üìä Veld Performance Regression Report

## Test Execution Summary

**Date:** $(date)
**Commit:** ${{ github.sha }}
**Branch:** ${{ github.ref_name }}
**Workflow:** ${{ github.workflow }}
**Run ID:** ${{ github.run_id }}

## Thresholds

| Level | Degradation | Action |
|-------|-------------|--------|
| Warning | >10% | ‚ö†Ô∏è Warn but pass |
| Critical | >20% | ‚ùå Fail build |

## Key Metrics

### Injection Performance
EOF

        # Add injection results if available
        if [ -f "target/regression-injection-results.json" ]; then
          echo '```json' >> REGRESSION_REPORT.md
          head -50 target/regression-injection-results.json >> REGRESSION_REPORT.md
          echo '```' >> REGRESSION_REPORT.md
        fi

        cat >> REGRESSION_REPORT.md << 'EOF'

### Throughput Performance
EOF

        if [ -f "target/regression-throughput-results.json" ]; then
          echo '```json' >> REGRESSION_REPORT.md
          head -50 target/regression-throughput-results.json >> REGRESSION_REPORT.md
          echo '```' >> REGRESSION_REPORT.md
        fi

        cat >> REGRESSION_REPORT.md << 'EOF'

## Recommendations

- Review any metrics with >10% degradation
- Check for recent code changes affecting performance
- Consider updating baselines if changes are intentional

---
*Generated by Veld Performance Regression Test Suite*
EOF

        # Replace $(date) with actual date
        sed -i "s/\$(date)/$(date)/g" REGRESSION_REPORT.md

        echo "‚úÖ REGRESSION_REPORT.md generated"
        cat REGRESSION_REPORT.md

    # Upload artifacts
    - name: Upload Regression Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-regression-results-${{ github.run_number }}
        path: |
          veld-benchmark/target/regression-*.json
          veld-benchmark/target/baseline/
          veld-benchmark/REGRESSION_REPORT.md
        retention-days: 30

    # Comment on PR if this is a PR
    - name: Comment on Pull Request
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: '## üìä Performance Regression Test Results\n\n' +
                  'Performance regression tests have completed. ' +
                  'Check the workflow run for detailed results.\n\n' +
                  '**Artifacts:** https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}\n\n' +
                  '‚ö†Ô∏è Review any warning or critical thresholds before merging.'
          })
